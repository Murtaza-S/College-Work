{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JO-Ybg6E1aNT",
    "outputId": "6a9d8c12-8f49-4eca-f522-cec2e6496ee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mrtz/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 3 ### number of BasicRNNCell layers\n",
    "n_neurons = 100 ### number of neurons in the network\n",
    "n_outputs = 10 ### outputs that represent digits from 0-9\n",
    "n_epochs = 50\n",
    "batch_size = 150\n",
    "train_keep_prob = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UUAfrR681jXi"
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42): ### it resests all created graph, it's required once re-defining of any placeholders, variables, shapes or model structures is needed\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "def generate_batch(train_data,train_labels, batch_size): \n",
    "    rnd_idx = np.random.permutation(len(train_data))\n",
    "    n_batches = len(train_data) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        x_batch = train_data[batch_idx]\n",
    "        y_batch = train_labels[batch_idx]\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hlFMMB8w1pR6"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data() ### loading the datasets\n",
    "x_train_nonvalid, x_train, y_train_nonvalid, y_train = train_test_split(x_train,y_train,test_size =0.083, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2uKyTjVrChh0"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32).reshape(-1, 28,28)/ 255.0  #reshaping and normalizing\n",
    "x_test = x_test.astype(np.float32).reshape(-1, 28,28)/ 255.0  #reshaping and normalizing\n",
    "x_train_nonvalid=  x_train_nonvalid.astype(np.float32).reshape(-1, 28,28)\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "y_train_nonvalid = y_train_nonvalid.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38J21tzO14_y",
    "outputId": "a88bd541-5c79-4c07-ceea-df773127c7ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the training set: 4980\n",
      "Length of the test set: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the training set:\", len(x_train))\n",
    "print(\"Length of the test set:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQjB6asd16sH",
    "outputId": "3dd9b713-7169-4d4e-b665-2793f9bc5c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set: (4980, 28, 28)\n",
      "Shape of the test set: (4980,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the training set:\", np.shape(x_train))\n",
    "print(\"Shape of the test set:\", np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_l2tsqq2Gj9",
    "outputId": "5f49b101-5b92-4472-bbde-821f7188a5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Inputs/X:0\", shape=(?, 28, 28), dtype=float32)\n",
      "Tensor(\"Inputs/y:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"Inputs/keep_probability:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 28 ### lengh of each row\n",
    "n_steps = 28 ### number of time steps\n",
    "#reset_graph()\n",
    "with tf.name_scope(\"Inputs\"):\n",
    "    X = tf.placeholder(tf.float32, [None, n_steps, n_inputs], name=\"X\")\n",
    "    y = tf.placeholder(tf.int32, [None], name=\"y\")\n",
    "    keep_prob = tf.placeholder_with_default(1.0, shape=(), name='keep_probability')\n",
    "print(X)\n",
    "print(y)\n",
    "print(keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJIRGPj92Ott"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nr5X14fiRjjK"
   },
   "outputs": [],
   "source": [
    "input = tf.unstack(X, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5X6xIuF72Rnc",
    "outputId": "15804df1-ed07-41ac-cb0c-f917599db00e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-344ec74b91fb>:7: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/mrtz/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:465: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrtz/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:421: UserWarning: `tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.SimpleRNNCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be \"\n",
      "/home/mrtz/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "/home/mrtz/.local/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "/home/mrtz/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstm_drop_cells = [tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=keep_prob)\n",
    "            for cell in [tf.nn.rnn_cell.BasicRNNCell(num_units = n_neurons, activation = tf.nn.relu)\n",
    "          for layer in range(n_layers)]]\n",
    "multi_cell = tf.keras.layers.StackedRNNCells(lstm_drop_cells)\n",
    "# multi_cell = tf.nn.rnn_cell.MultiRNNCell(lstm_drop_cells)\n",
    "#rnn_cell = tf.nn.rnn_cell.BasicRNNCell(lstm_cells_drop)\n",
    "outputs, states = tf.nn.static_rnn(multi_cell, input, dtype = tf.float32) ### states return final state (last output) of the multi_layer_cell\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"Loss\"):\n",
    "    states_concat = tf.concat(axis=1, values=states, name='states_reshape')\n",
    "    dense1 = tf.keras.layers.Dense(states_concat, 64, name='dense_1')\n",
    "    dense2 = tf.keras.layers.Dense(dense1, 32, name='dense_2')\n",
    "    logits = tf.keras.layers.Dense(dense2, n_outputs, name='output_layer')\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=tf.reshape(logits, shape=(-1, n_outputs)), name='softmax_cross_entropy')\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')\n",
    "    loss_summary = tf.summary.scalar('loss_summ', loss)\n",
    "\n",
    "with tf.name_scope(\"Train\"):    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, name='Adam_optimizer')\n",
    "    training_optimizer = optimizer.minimize(loss, name='training_Adam')\n",
    "\n",
    "with tf.name_scope(\"Evaluation\"):        \n",
    "    correct = tf.nn.in_top_k(tf.reshape(logits, (-1, n_outputs)), y, 1, name='inTopK')\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='Accuracy')\n",
    "    accuracy_summary = tf.summary.scalar('Accuracy_Summ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QdxW0i-X2mIK"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "#saver = tf.train.Saver()\n",
    "\n",
    "x_test = x_test.reshape((-1, n_steps, n_inputs)) ### reshaping test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "u7M2wXOW27k1"
   },
   "outputs": [],
   "source": [
    "best_loss = np.infty                ### parameters for early stopping\n",
    "epochs_without_progress = 0         ### once epochs_without_progress reaches the value\n",
    "max_epochs_without_progress = 2    ### of max_epochs_without_progress, the model stops and saves last parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0RsN09R03Bbt"
   },
   "outputs": [],
   "source": [
    "#acc_list, acc_test_list, loss_list, loss_test_list = [], [], [], [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYpHtni_3KF6",
    "outputId": "daf53951-1269-4b5a-8d7c-77c91f4dc4f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 \tValidation accuracy: 51.145% \tTest accuracy: 52.470% \tLoss: 1.135\n",
      "Epoch 4 \tValidation accuracy: 68.574% \tTest accuracy: 69.470% \tLoss: 0.832\n",
      "Epoch 6 \tValidation accuracy: 74.116% \tTest accuracy: 73.640% \tLoss: 0.691\n",
      "Epoch 8 \tValidation accuracy: 76.044% \tTest accuracy: 73.860% \tLoss: 0.638\n",
      "Epoch 10 \tValidation accuracy: 76.747% \tTest accuracy: 76.740% \tLoss: 0.625\n",
      "Epoch 12 \tValidation accuracy: 79.458% \tTest accuracy: 77.510% \tLoss: 0.531\n",
      "Epoch 14 \tValidation accuracy: 80.141% \tTest accuracy: 79.340% \tLoss: 0.518\n",
      "Epoch 16 \tValidation accuracy: 81.687% \tTest accuracy: 79.600% \tLoss: 0.475\n",
      "Epoch 18 \tValidation accuracy: 80.703% \tTest accuracy: 79.460% \tLoss: 0.498\n",
      "Epoch 20 \tValidation accuracy: 81.365% \tTest accuracy: 80.940% \tLoss: 0.476\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    epoch = 0\n",
    "    while epoch < n_epochs:\n",
    "        for x_batch, y_batch in generate_batch(x_train, y_train, batch_size): ### generating batches for x/y_train\n",
    "            x_batch = x_batch.reshape((-1, n_steps, n_inputs)) ### reshape to the format define for X placeholder\n",
    "            \n",
    "            ### for x_batch/y_batch data we feed keep_prob values for 0.8\n",
    "            sess.run(training_optimizer, feed_dict={X: x_batch, y: y_batch, keep_prob: train_keep_prob})\n",
    "        acc_batch, loss_batch, acc_sum, loss_sum = sess.run([accuracy, loss, accuracy_summary, loss_summary], feed_dict={X: x_train, y: y_train, keep_prob: train_keep_prob})   \n",
    "        \n",
    "        ### during evaluation on test set, no dropout required, keep_prob has default value (1.0)    \n",
    "        acc_test, loss_test, acc_test_sum, loss_test_sum = sess.run([accuracy, loss, accuracy_summary, loss_summary], feed_dict={X: x_test, y: y_test})\n",
    "               \n",
    "        epoch += 1\n",
    "        if epoch % 2 == 0:\n",
    "            print(\"Epoch\", epoch,\n",
    "                  '\\tValidation accuracy: {:.3f}%'.format(acc_batch * 100), '\\tTest accuracy: {:.3f}%'.format(acc_test * 100), '\\tLoss: {:.3f}'.format(loss_batch))\n",
    "            #saver.save(sess, checkpoint_path)\n",
    "            if loss_batch < best_loss:\n",
    "                #saver.save(sess, final_model_path)\n",
    "                best_loss = loss_batch\n",
    "                epochs_without_progress = 0\n",
    "            else:\n",
    "                epochs_without_progress += 1\n",
    "                if epochs_without_progress == max_epochs_without_progress:\n",
    "                    print('Early Stopping')\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Assignment_10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
